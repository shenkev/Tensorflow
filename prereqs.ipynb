{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [1., 2., 3.]\n",
    "print a\n",
    "\n",
    "b = [[1., 2., 3.], [4., 5., 6.]]\n",
    "print b\n",
    "\n",
    "c = [[[1., 2., 3.]], [[7., 8., 9.]]]\n",
    "print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node1 = tf.constant(3.0, dtype=tf.float32)\n",
    "node2 = tf.constant(4.0) # implicitly tf.float32\n",
    "print (node1, node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print sess.run([node1, node2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node3 = tf.add(node1, node2)\n",
    "print node3\n",
    "print sess.run(node3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "node4 = a + b # shortcut for tf.add(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print sess.run(node4, {a: 3, b: 4.5}) # pass in values\n",
    "print sess.run(node4, {a: [1, 2], b: [3, 4]}) # pass in arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node5 = node4 * 3\n",
    "print sess.run(node5, { a: 3, b: 4 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable([.3], dtype=tf.float32)\n",
    "b = tf.Variable([-.3], dtype=tf.float32)\n",
    "x = tf.placeholder(tf.float32) # you only specify the type, not the dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear_model = W * x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer() # need to explicitly initialize variables\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print sess.run(linear_model, { x: [1, 2, 3, 4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.float32)\n",
    "squared_err = tf.square(linear_model - y)\n",
    "loss = tf.reduce_sum(squared_err) # err = (y^ - y)^2\n",
    "print sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wbest = tf.assign(W, [-1.]) # assign W to [-1.], changes are made for relevant models\n",
    "bbest = tf.assign(b, [1.])\n",
    "sess.run([Wbest, bbest])\n",
    "print sess.run(loss, { x: [1,2,3,4], y:[0,-1,-2,-3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init) # reinitialize model variables using global_variables_initializer, W and b are set back to 0.3, -0.3\n",
    "iters = 1000\n",
    "for i in range(iters):\n",
    "    sess.run(train, { x: [1, 2, 3, 4], y: [0, -1, -2, -3]})\n",
    "\n",
    "print sess.run([W, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High level API\n",
    "features = [tf.contrib.layers.real_valued_column(\"x\", dimension=1)]\n",
    "\n",
    "estimator = tf.contrib.learn.LinearRegressor(feature_columns=features)\n",
    "\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "\n",
    "input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\": x_train}, y_train, batch_size=4, num_epochs=1000)\n",
    "eval_fn = tf.contrib.learn.io.numpy_input_fn({\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000)\n",
    "\n",
    "estimator.fit(input_fn=input_fn, steps=1000) # call session.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = estimator.evaluate(input_fn = input_fn)\n",
    "eval_loss = estimator.evaluate(input_fn = eval_fn)\n",
    "print \"train loss: %r\" % train_loss\n",
    "print \"eval loss: %r\" % eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# writing custom models, implement linear regression using low level API\n",
    "# we need to pass a function that takes the following parameters:\n",
    "# - features\n",
    "# - labels\n",
    "# - mode\n",
    "# and returns the following things to the Estimator class:\n",
    "# - predictions, e.g. y=wx+b\n",
    "# - loss\n",
    "# - training steps: (what optimizer you're using and how the iteration number \"global_step\" is being updated)\n",
    "def model(features, labels, mode):\n",
    "    # define the parameters for this model\n",
    "    W = tf.get_variable(\"W\", [1], dtype=tf.float64) # shape is [1]\n",
    "    b = tf.get_variable(\"b\", [1], dtype=tf.float64) # these seem to be globally stored\n",
    "    # - predictions\n",
    "    y = W*features['x'] + b\n",
    "    # - loss\n",
    "    loss = tf.reduce_sum(tf.square(y - labels))\n",
    "    # training steps\n",
    "    global_step = tf.train.get_global_step() # the iteration number seems to be counted globally... maybe for paralell stuff?\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01) # this must be the step size\n",
    "    train = tf.group(optimizer.minimize(loss), tf.assign_add(global_step, 1)) # group these two operations (I guess make sure they both finish? why?)\n",
    "    \n",
    "    return tf.contrib.learn.ModelFnOps(mode=mode, predictions=y, loss=loss, train_op=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = tf.contrib.learn.Estimator(model_fn = model) # inject our model class/function\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\": x_train}, y_train, 4, num_epochs=1000)\n",
    "eval_input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\": x_eval}, y_eval)\n",
    "# we have 2 things here: the model with how to calculate loss and gradients and the learning data and loop parameters\n",
    "estimator.fit(input_fn = input_fn) # I don't understand why you need steps and batchsize+epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-07-30-22:46:30\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpeiRaVn/model.ckpt-2\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-30-22:46:30\n",
      "INFO:tensorflow:Saving dict for global step 2: global_step = 2, loss = 167.552\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'eval_input_fn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-24d7cce2e77d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Here we evaluate how well our model did.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0meval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train loss: %r\"\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"eval loss: %r\"\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0meval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eval_input_fn' is not defined"
     ]
    }
   ],
   "source": [
    "# Here we evaluate how well our model did. \n",
    "train_loss = estimator.evaluate(input_fn=input_fn)\n",
    "eval_loss = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train loss: %r\"% train_loss)\n",
    "print(\"eval loss: %r\"% eval_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
